---
title: "censusTools - An R package for integrating and harmonising census statistics"
author: Steffen Ehrmann, Ralf Seppelt, Navin Ramakutty, Carsten Meyer
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    fig_caption: yes
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_float: yes
  bookdown::pdf_document2:
    fig_caption: yes
    highlight: pygments
    keep_tex: yes
    number_sections: yes
    toc: no
bibliography: references.bib
documentclass: article
fontsize: 12pt
linestretch: 1.15
link-citations: yes
urlcolor: blue
csl: harvard-staffordshire-university.csl
tags:
- census
- standardisation
- ...
biblio-style: apalike
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(censusTools)
```

# Abstract

Humans gather information about a wide variety of phenomena in the form of census statistics.
Those are typically based on recuring surveys that relate some quantity of socioeconomic, land-use, or environmental variables to a particular territorial area.
We are interested in those data out of an economic interest, to assess environmental impacts or to support political decisions.

Not only in the context of Sustainable Development Goals such data need to be harmonised across broad temporal and spatial extents up to the global scale.
Mostly the issue is not to gather any data at all, but to make data across various sources compatible with one another.
This obstacle has so far not been tackled to a degree that would be satisfying with respect to transparency and reproducability.
However, to enable re-usability and thus future-proof the vast and often laboriously collected (and perhaps simplified) data, a transparent and reproducible workflow should be guaranteed.

Here we introduce a software package (written in `R`) that allows the user to build up integrated and harmonised databases of a wide variety of census statistics, which are typically related to some sort of territorial unit. Databases set up with this tool are both internally consistent and can be combined with other databases assembled with this tool.
We exemplify the usage by showcasing some of the important steps we carry out for an ongoing project on spatio-temporal dynamics of land-use.
The package can be used for any kind of census statistics that shall be connected to territorial units.

# Introduction

Gathering census statistics to aggregate them is a laborious and cumbersome task.
The aim of a census is to tally the overall population of some group of entities of interest.
A census is thus often perceived as the opposite of a sampling, which merely tries to estimate the overall population based on a representative subset.

To enable an accurate assessment of any current situation, systematic census is crucial. A census is carried out to assess, for instance, the livelihood of people, to monitor agricultural production for food security, to inventory all sorts of commodities or products out of economic reasons or to assess the environmental impact of human activities with the help of checklists of plant and animal species.

While we already learn quite a bit from national censuses, there is a large incentive to aggregate several of such efforts across larger spatial or temporal scales to infer on phenomena that can only be perceived at those larger scales.
For example, to successfully achieve several of the sustainable development goals, we need to recognize and acknowledge global phenomena that have unfolded during the course of decades (*go into more details/examples here?!*).
Moreover, we may want to combine census statistics from various sources that may cover the same spatio-temporal extent or that may be related to one another.
For instance, combining several subsets that make up a larger area and considering the different sources of errors for small and large scale data lets us infer on uncertainties that may be introduced by all of the data sources.

This entails however that data from multiple, heterogeneous sources often have to be harmonised and integrated across several (spatio-temporal) scales. On top of the considerations and assumptions that go into individual nation level censuses, harmonizing them requires to consider yet another level of heterogeneity and assumptions.


*Shall we also include a more theoretical section on how these census data are typically "meso-scale" data that fill an important gap between in-situ local scale data and larger scale data, cf Petr Keils topic?*

The [United Nations](https://unstats.un.org/unsd/demographic/sources/census/docs/P&R_Rev2.pdf) defines the essential features of population and housing censuses as "individual enumeration, universality within a defined territory, simultaneity and defined periodicity", and recommends that population censuses be taken at least every 10 years. *Agricultural censuses are defined by the FAO as follows...*.
Ecological assessments of plant or animal communities are typically not recorded in a census but merely sampled. (*more details on that*) [@Koenig2019]

Typically census data are counted per a specific spatial unit. In other words, a census can have various properties, one of which is the location at which the recorded variables are true.
For monitoring or modelling system responses with a spatial dimension it is thus necessary to make census data and spatial information align perfectly.

A *sample* of subsets of a population should be treated different than the *census* of the (complete) population out of statistical considerations (*should we mention details on that?*).
The *degree of detail/precision/...* that comes with the difference between \"sampling\" and \"taking a census\" is an important property based on which we may want to select certain statistics under certain conditions.

*CM: Also, refer to some specific data integration processes that are currently underway but slowed down due to lack of such tools. E.g. FAO and IFPRI spend personnel funds each year on people like Ulrike who currently do this by hand. All these institutes are underfunded and  understaffed and should thereby benefit from such a tool.*

*A couple of words on how census data are typically sampled and relationships between various census efforts: http://www.fao.org/world-census-agriculture/methodology/en/*

*A couple of words on why census data are recorded: http://www.fao.org/fileadmin/templates/ess/documents/world_census_of_agriculture/chapter02_r7.pdf; needs more sources of information*

**Outline issues**

Territory outlines may change with time. *More on how this becomes problematic*

Working with census statistics entails not only finding orientation in a vast number of different formats the data are provided in, but also associating those tabular information to the spatial information for which it often is recorded.

With the advancement of GIS know-how, many census stats are provided together with the spatial information based on which they have been derived. 
When census data are aggregated for a particular territorial unit, even if they are originally recorded in the form of point records, the spatial extent of that unit needs to be available. 
However, often those spatial information are not taken from a standardized set of spatial geometries, such as the GADM data-set [REF], but are derived or manually created from (outdated) local maps.
Various sources of error make the spatial data deviate from a possible standard. Those could be:

1. Choice of the wrong or no particular coordinate reference system,
2. systematic errors when manually copying paper maps with digitizing tools,
3. deviations that emerge when vectorising and processing raster maps (either raster-outline as boundary of the spatial unit, or a deviating boundary when the raster-boundary is smoothed with some unknown smoothing function) or
4. disagreement on territorial boundaries.

These eventually result in a very general source of inconsistency, when including or excluding certain (point) sources or other parts of information due to deviating spatial extents, or when census data are innately related to the area or topological information of territorial units.

# The challenge
**This chapter shall clearly state/summarise the open aspects and what of that we want to solve with `censusTools`.**

A wide variety of census data are available. *Outline two/three examples and their specifities*; *Outline what they have in common and which differences between them need to be considered.*

Census data and geometries must be associated to one another, possibly on a global scale and so that they are compatible across distinct efforts.

This entails:

1. Administrative/territorial units must be matched *across different languages*.
2. Likewise, particular key variables (species, commodities, basically any categories) might have different values in different languages or censuses and they must also be matched.
3. To make variables comparable across different efforts, there must be a standard for naming variables (*SE: I would thus suggest in this paper that naming shall follow the Darwin Core, this would take the burden of defining such a naming standard off of our shoulders and would also assert that future compatibility is managed by the Darwin Core rules*).
4. Moreover, we believe that such efforts must be *fully transparent and reproducible*.

A generalised framework for managing census data that would be related to spatial information, irrespective of the covered variables, was devised and shall be presented in this paper.

# Description of `censusTools`

This section describes briefly what `censusTools` does. In the following subsections technical details are outlined.

Typically some sort of polygons outlining territorial boundaries (here called *geometries*) and some sort of tables outlining the quantities of particular variables (here called *census tables*) shall be handled with `censusTools`.

**Set project variables**

A typical workflow (Fig. 1) would initially consist of setting up project variables.
Those variables are the categorical variables for which the census covers quantities, such as socio-economic groups of people, animal species or agricultural commodities.
For each of the variables an *index* and a *translation table* are required (*see section "Index and translation tables"*).
An index contains at least the values of the target variable (e.g. 'maize', 'wheat', 'rice' for the variable 'commodities'), unique IDs for each value and arbitrary data that describe the values further (e.g. details on collecting/sampling the data, the scientific name or a description).
A translation table contains at least the values that should be translated, the values of the translated target variable (same terms as in the index) and a statement as to how the translations have been created.

**Register input tables**

In a second step first of all some relevant data-series (i.e. specific series of data which are delineated from other series due to their data format) and then the source-files of geometries and census tables are registered in respective inventory tables each.
While project variables are set up only once, this second step will be carried out as often as new data are added to the database.
The underlying functions give instructions, monitor and document progress and assert that all files are available in the correct directory (*see section "The directory structure"*).
Additionally, they create unique IDs for data-series, geometries and census tables.
The resulting inventory tables document which geometry and census files are part of the data-base, where and when they have been stored and which ID they have.

**Normalise data**

In a third step, both geometries and census tables are harmonised and integrated (i.e. *normalised*) into a standardised data-base structure.
Census tables typically contain information that are aggregated for certain territorial units and thus it makes sense, from an efficiency point of view, that the territorial units are first normalised, so that the census tables can simply be joined to them.
Both, geometries and census tables are aggregated per nation (*see section "Normalising spatial data" and "Normalising census data"*).

Eventually, the values of categorical variables in the census tables are mapped to their indices to reduce the size of the overall database.
Such variables may prominently be the territorial units (*see section "Territory ID"*), agricultural commodities or basically any variable that is defined by the user.

![Fig. 1: Overview of the general workflow employed by `censusTools`.](data_management_overview.svg)

## Index and translation tables

Index tables shall at least contain the values of the target variables and an associated ID. Moreover, it can contain all sort of additional information or alternative IDs that could be selected based on the additional information. For the example case on agricultural commodities, `simpleName` and `faoID` are target variable and ID. Additional information are contained in the columns:

* `primary`, which specifies whether a commodity is a primary or a processed commodity, 
* `faoName`, which stores the official FAO name of the commodity,
* `faoGrouID` and `faoGroupName`, the ID and name of the commodity group,
* `canonicalName`, the scientific name of the primary commodities and
* `definition`, which gives additional, contextual information that may serve to delineate the commodity in unclear cases.

When handling data from various data providers that are active in different languages and who don't follow any common standards for data curation or don't have shared ontologies, it is expected that plenty of variables will contain values that don't match.
In those cases so-called gazetteers can help to find sort of a standard.
For instance, the GADM data-set comes with alternative names for numerous territorial units, which can be used for alternative matching. The GBIF data-set contains the backbone taxonomy [REF], which could be used for this purpose when it comes to species (*SE: additional/other/better suggestions for widely known tables of that kind?*).
However, since it can't be guaranteed that all data providers use only names that have been covered by the included translation tables, the function `translateTerms()` allows that new mappings between so far not recorded terms and target terms are made or that additional gazetteers are read in.

Translation tables consist of two parts, a translation section and a look-up section. They are organised in the three columns:

* `origin`, which contains all native terms as they appear in different census data-sets, 
* `target`, their unified translations and 
* `source`, which documents how and when the translation has been carried out. 

The upper part of the table contains all `origin <-> target` mappings.
In this section one would insert an already existing translation table.
The lower part contains the target terms to which new, unmapped terms should be translated.
In this section of the translation table one would insert a standardised ontology, when encountering new terms, those target terms are used for fuzzy matching.
However, here the column `origin` remains empty and the column `source` must contain the value *original* for the function `translateTerms()` to recognise this distinction.

| origin | target | notes |
| :- | :- | :- |
| toTranslate | translated | translateTerms() on 2019-02-28|
| anotherOne | itsTranslation | translateTerms() on 2019-02-28|
| ... | ... |  |
|  | term1 | target |
|  | term2 | target |
|  | term3 | target |

Here, a list of the three most highly matched terms based on the Levenshtein distance [REF] is returned, from which the user has to chose.
Moreover, before the translated data are finally entered into the database, they are checked against this list so that no new translations violate the ontological consistency (*SE: I still have to make sure that this feature is actually implemented*).

## The directory structure

`censusTools` relies on a rather rigid directory structure and thus creates this structure itself, when the function `setPath()` is called for the first time.
Within the primary project directory the two directories `./cT_geometries/` and `./cT_census/` are created.
Within both of those directories, the following directories are created: 

* `incoming/`, a tentative location for new data, 
* `meta/`, a place for related data, 
* `original_datasets/`, an archive of the original, unmodified files, 
* `stage1/` and `stage2/`, which store different qualities of modified data. In `stage1` the registered data are stored in a standardised format, geometries are stored as GeoPackage files [REF, https://www.opengeospatial.org/standards/geopackage] and census tables are stored as comma-separated value files with a UTF-8 encoding. In `stage2` the nation specific database files are stored.

## Normalising spatial data

To normalise geometries a large computational effort is required, but much automisation is possible.
The geospatial data-base is built up from a basis that is provided by the user.
It does not urge the user to employ for instance the GADM data-set [REF], even though this is the recommended starting point recently.
This basic geo-spatial data-set should provide the hierarchical administrative organisation and the names of territorial units by which the following input shall be organised.

`censusTools` matches territorial units not based on the administrative names, as those are less reliable than the spatial extent.
It matches administrative units by their spatial overlap, with a so-called *spatial join* [REF?].


## Normalising census data

Normalising census tables can only be automated to a certain degree.
Most data providers don't follow a standard format when it comes to the provided data.
All sort of messy tables need to be transformed and, to our knowledge, this is nothing a computer could recognise autonomously to date.
`censusTools` relies on the *rectr* R-package [REF], which takes a list of instructions that describe where which data are located in a particular spreadsheet, and reorganises the information into a rectangular table that can be processed with a *dplyr*-based pipeline [REF].

Census stats are eventually stored in tables, where the data source(s), territorial and temporal information and the recorded variables are present in the following columns:

* `cenID` (census ID) and `geoID` (geometry ID) hold IDs that relate the respective row to a particular census and geometry data provider.
Often similar or the same data are provided by several distinct data providers or by data aggregators.
Those two IDs thus allow quality assessments of the data and ensure that the data provenance is properly documented.
* `ahID` (administrative hierarchy ID) represents the ID that is also recorded in the respective spatial data and which relates census stats to territorial units.
* `time-step` would be a column that denotes the time for which the census has been recorded. It could take any form, for example a combination of year and day-of-the-year (doy), merely the year or the month within a year, etc. This may depend on the temporal resolution of the source data-sets or of the questions that shall be addressed with the acquired data.
* `variable(s)` can be any number of columns, each of which would contain either keys (typically categorical variables such as agricultural commodities or species) or values (typically some sort of quantity of the key, such as "production" and "yield" or "abundance").

| ID | cenID | geoID | ahID |  time-step | variable 1 (key)<br>e.g. commodity |  variable 2 (value)<br>e.g. production |
| :- | :- | :- | :--- | :--- | :---- | :---- |
| 1 | 1 | 1 | 070017008 | 2016 | maize | 15000 |
| 2 | 1 | 1 | 070017008 | 2016 | wheat | 12000 |
| 3 | 1 | 1 | 070017008 | 2017 | ... | |
| ... |  |  |  |  |  | |

Both, `timestep` and `variables` are recorded indifferent of their units, which are recorded separately in the meta data. (*SE: I still need to assert that the units are actually recorded; my idea would be that data should be recorded at the finest level at which they are reported so that aggregation only happens later, when the model is computed; which may not even be needed for some more advanced models in the future.*).

## Territory ID

Administrative territorial units are often subsets of larger units and eventually of nations.
To denote those units, we use a particular ID that is unique per unit, irrespective of the administrative level and which captures the hierarchical administrative information.

At each administrative level, territorial units are enumerated along their alphabetic sequence with a three-digit ID, starting from 1 through their count. The \"children\" within each higher level unit (\"parent\") likewise restart at 1 and are enumerated along their alphabetic sequence.
The nestedness is represented by a sequence of those three digit IDs, where parent units are placed before their children. For example, `070'017'008` is the community of Tammelin (8th community) in Tartumaa (17th county), Estonia (70th nation).
This code is extended with more sets of unit-IDs, when working on the fourth/fifth/... administrative level.

(*I have started a chapter in the discussion, where I outline how temporal and territorial shifts are dealt with in `censusTools`*)

*I realised that the package also needs an option to join census and spatial data by an ID that may already be in the data, such as FIPS for the US census data.*



# Discussion

*what do other packages that `censusTools` doesn't do? -> CM: more precisely, what cool new things will now be facilitated with these new tools?), limitations (e.g. against other tools or in general, but focusing on the specific challenges the toolls are meant to overcome), etc*

*what can `censusTools` generally not be used for?* -> It is not a tool that automates extraction of census data from messy tables/spreadsheets.
For that task, check out the R-package `rectr`.
However, `censusTools` makes use of this package to organize a particular subset of messy data, agricultural census data that typically provide a narrow, predefined set of variables and meta information.

*Discuss, based on parts that have been mentioned in the introduction, how `censusTools` can actually deal with the outlined challenges and the requirements of different kinds of census data.*

## Dealing with temporal changes

As the territory ID does not depend on any topological information of the territorial units, it allows to assign individual IDs to units that are valid only for a certain period of time.

(*SE: I still have to make sure that this is properly reflected by what the code does*)

## Dealing with disputed areas

As the territory ID does not depend on any topological information of the territorial units, it allows to assign individual IDs to units that may be disputed territories.

(*SE: I still have to make sure that this is properly reflected by what the code does*)


# Outlook

Perhaps talk about how to implement this for use in citizen science and for building large and exhaustive open databases.

*mention a couple of words about LUCKINet?! -> CM: Could be done in a paragraph on different initiatives that could make good use of this tool. Could also mention e.g. WorldPop for population census data, GIFT for regional checklists, etc.* 

*How does `censusTools` facilitate interoperability with other tools (that may not exist yet)?*

# Session Info
*this should probably be replaced by a proper list of packages that are used for `censusTools`*
```{r}
sessionInfo()

```

# Miscellaneous/Notes/Comments

## Comments on editorial decisions

***Steffen***

1. After reading more on it, it seems that it would make sense to use *territorial unit*, which is at least in the European legislative speak the commonly used term: https://en.wikipedia.org/wiki/Nomenclature_of_Territorial_Units_for_Statistics.
Also, "administrative unit" seems to be often used to describe a unit that deals with administrative stuff within an organisation, like a school, etc.
2. I think it is not needed to specify in detail in the title that we only deal with *census stats that are related to territorial units*, as this is typically the case for the concept of "census" (https://en.wikipedia.org/wiki/Census).
3. I am making a deliberate distinction between *attribute* and *property* (https://stackoverflow.com/a/21566583)

## Known tools and pipelines (based on R)

*this list is to gather information against what `censusTools` could be compared.*

Implement mapping in shiny: https://shiny.rstudio.com/tutorial/written-tutorial/lesson5/

[Combining Australian Census data with the Same Sex Marriage Postal Survey in R](https://medium.com/@miles.mcbain/combining-australian-census-data-with-the-same-sex-marriage-postal-survey-in-r-39d9b2082249)

[Extract US Census 2010 data with data.table and dplyr](https://gl-li.netlify.com/2017/08/29/process-2010-census-data-with-data-table/)

[Creating beautiful demographic maps in R with the tidycensus and tmap packages](http://zevross.com/blog/2018/10/02/creating-beautiful-demographic-maps-in-r-with-the-tidycensus-and-tmap-packages/)

[Compare US metropolitan area characteristics in R with tidycensus and tigris ](https://walkerke.github.io/2017/06/comparing-metros/)

[A Guide to Working with US Census Data in R](https://rconsortium.github.io/censusguide/), [R-packages](https://rconsortium.github.io/censusguide/r-packages-all.html)

## (Important) papers on the topic

@Aalders2006: *Modelling land use change is often constrained by imperfect and incomplete data sources. This paper explores three modelling methodologies and their ability to predict agricultural land use on the basis of information from the Scottish Agricultural Census.*

@Forclaz2016: *This article provides a history of the First World Agricultural Census of 1930, an ambitious international attempt to evaluate world agricultural resources through the compilation of global statistics on crops, livestock, and agricultural production.*

@Monfreda2008: *Here we present land use data sets created by combining national, state, and county level census statistics with a recently updated global data set of croplands on a 5 min by 5 min (~10 km by 10 km) latitude-longitude grid.*

@Imbach2015: *We present here an agricultural statistics database of the entire Amazonia region, with a harmonised description of crops and pastures in geospatial format, based on administrative boundary data at the municipality level. The spatial coverage includes countries within Amazonia and spans censuses and surveys from 1950 to 2012.*

@Otto2015: *Subnational socio-economic datasets are required if we are to assess the impacts of global environmental changes and to improve adaptation responses. Institutional and community efforts should concentrate on standardization of data collection methodologies, free public access, and geo-referencing.*

@Ricciardi2018, @Ricciardi2018a: *We examine variations in crop production by farm size using a newly-compiled global sample of subnational level microdata and agricultural censuses covering more countries (n=55) and crop types (n=154) than assessed to date.*

@Waha2016: *Surveys for more than 9,500 households were conducted in the growing seasons 2002/2003 or 2003/2004 in eleven African countries: Burkina Faso, Cameroon, Ghana, Niger and Senegal in western Africa; Egypt in northern Africa; Ethiopia and Kenya in eastern Africa; South Africa, Zambia and Zimbabwe in southern Africa.*

## links to look through

https://ajs.data-analysis.at/index.php/ajs/article/view/vol39,%20no4%20-%202

https://www.tandfonline.com/doi/abs/10.1080/136588198241590

https://www.aeaweb.org/articles?id=10.1257/aer.p20161061

https://www.journals.uchicago.edu/doi/abs/10.1086/693916

https://search.proquest.com/openview/eb6bdc49aa2678f832fcf014ca09ae21/1?cbl=105444&pq-origsite=gscholar

https://www.jstor.org/stable/1403545?seq=1#metadata_info_tab_contents

http://www.fao.org/economic/ess/countrystat

https://link.springer.com/chapter/10.1007/978-3-319-44421-5_3

https://www.annualreviews.org/doi/abs/10.1146/annurev-statistics-041715-033713

*there is still more...*

https://www.ipums.org/

https://datacatalog.worldbank.org/

https://en.wikipedia.org/wiki/Gazetteer

## Packages

*perhaps include some statistics about how many packages there are*

*explain briefly what the key packages are used for and how this relates to `censusTools`*

tidycensus: https://walkerke.github.io/tidycensus/, https://juliasilge.com/blog/using-tidycensus/

censusapi: https://github.com/hrecht/censusapi, https://cran.r-project.org/web/packages/censusapi/vignettes/getting-started.html

[tigris: An R Package to Access and Work with Geographic Data from the US Census Bureau](https://journal.r-project.org/archive/2016/RJ-2016-043/RJ-2016-043.pdf)

## Sources of census statistics and associated geometries

Lots of information on processing census stats (in R) is based on the "American Community Survey" and "Decennial Data from the US Census". 

[List of national and international statistical services](https://en.wikipedia.org/wiki/List_of_national_and_international_statistical_services)

[Spatial Data in Geographic Information System Format on Agricultural Chemical Use, Land Use, and Cropping Practices in the United States](https://pubs.usgs.gov/wri/wri944176/)

[AGRICULTURE CENSUS IN INDIA](http://iasri.res.in/ebook/TEFCPI_sampling/AGRICULTURE%20CENSUS%20IN%20INDIA.pdf)

# References